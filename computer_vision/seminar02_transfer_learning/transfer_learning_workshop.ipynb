{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Заполненный семинарский ноутбук и необходимые данные доступны по ссылке: https://cloud.mail.ru/public/D2HE/DcgevU7e7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from torchnet import meter # pip install torchnet\n",
    "import tqdm\n",
    "import math\n",
    "import shutil\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "def show_image(image, figsize=(16, 9), reverse=True):\n",
    "    plt.figure(figsize=figsize)\n",
    "    if reverse:\n",
    "        plt.imshow(image[...,::-1])\n",
    "    else:\n",
    "        plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создадим класс модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"3x3 convolution with padding\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.activation(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.activation(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class BasicBlockV3(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlockV3, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(inplanes)\n",
    "        self.conv1 = conv3x3(inplanes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.conv2 = conv3x3(planes, planes, stride)\n",
    "        self.bn3 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.bn1(x)\n",
    "        out = self.conv1(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.activation(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.activation(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.activation(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.activation(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class HeadE(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, emb_size):\n",
    "        super(HeadE, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, emb_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        inputs = inputs.view(inputs.size(0), -1)\n",
    "        x = self.fc(inputs)\n",
    "        x = self.bn2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResNetFR(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, emb_size=128, head_size=7*7*512, preserve_resolution=True, **kwargs):\n",
    "        self.inplanes = 64\n",
    "        super(ResNetFR, self).__init__()\n",
    "        if preserve_resolution:\n",
    "            self.body = nn.Sequential(\n",
    "                nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.PReLU())\n",
    "        else:\n",
    "            self.body = nn.Sequential(\n",
    "                nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.PReLU(),\n",
    "                nn.MaxPool2d(\n",
    "                    kernel_size=3,\n",
    "                    stride=2,\n",
    "                    padding=1))\n",
    "            \n",
    "        self.head_size = head_size\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0], stride=2)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        \n",
    "        if kwargs.get(\"emb_model\", False):\n",
    "            self.head = HeadE(self.head_size, self.emb_size)\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def set_parameter_requires_grad(self, layers=set()):\n",
    "        \"\"\"Sets parameters from the heads listed in layers to requires_grad=True.\n",
    "        Args:\n",
    "            layers: Set  of name strings for heads to set requires_grad=True, e.g. {'pose_model'}.\n",
    "        \"\"\"\n",
    "        if layers:\n",
    "            for name, param in self.named_parameters():\n",
    "                if name.split(\".\")[0] in layers:\n",
    "                    param.requires_grad = True\n",
    "                else:\n",
    "                    param.requires_grad = False\n",
    "\n",
    "    def set_parameter_to_train(self, layers=set()):\n",
    "        \"\"\"Sets parameters from the heads listed in layers to train mode.\n",
    "        Args:\n",
    "            layers: Set  of name strings for heads to set to train mode, e.g. {'pose_model'}.\n",
    "        \"\"\"\n",
    "        model.eval()\n",
    "        for layer in layers:\n",
    "            head = getattr(self, layer)\n",
    "            head.train()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = list()\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        device = x.device\n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        x = self.body(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        if hasattr(self, 'head'):\n",
    "            embeddings = self.head(x)\n",
    "        else:\n",
    "            embeddings = torch.zeros(batch_size, self.emb_size).detach()\n",
    "\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_resnet(depth, **kwargs):\n",
    "\n",
    "    if depth >= 101:\n",
    "        block = Bottleneck\n",
    "    else:\n",
    "        block = BasicBlockV3\n",
    "\n",
    "    if depth == 18:\n",
    "        units = [2, 2, 2, 2]\n",
    "    elif depth == 34:\n",
    "        units = [3, 4, 6, 3]\n",
    "    elif depth == 49:\n",
    "        units = [3, 4, 14, 3]\n",
    "    elif depth == 50:\n",
    "        units = [3, 4, 14, 3]\n",
    "    elif depth == 74:\n",
    "        units = [3, 6, 24, 3]\n",
    "    elif depth == 90:\n",
    "        units = [3, 8, 30, 3]\n",
    "    elif depth == 100:\n",
    "        units = [3, 13, 30, 3]\n",
    "    elif depth == 101:\n",
    "        units = [3, 4, 23, 3]\n",
    "    elif depth == 152:\n",
    "        units = [3, 8, 36, 3]\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"no experiments done on num_layers {}, you can do it yourself\".format(depth))\n",
    "\n",
    "    model = ResNetFR(block, units, **kwargs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = build_resnet(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model with emb head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = build_resnet(100, emb_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"fr.pth.tar\", map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_ft.load_state_dict(checkpoint, strict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Добавим голову для предсказания пола"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import weight_norm\n",
    "from torch.nn import init\n",
    "\n",
    "\n",
    "class ResNeXtBottleneck(nn.Module):\n",
    "    \"\"\"\n",
    "    RexNeXt bottleneck type C (https://github.com/facebookresearch/ResNeXt/blob/master/models/resnext.lua)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, stride, cardinality, widen_factor):\n",
    "        \"\"\" Constructor\n",
    "        Args:\n",
    "            in_channels: input channel dimensionality\n",
    "            out_channels: output channel dimensionality\n",
    "            stride: conv stride. Replaces pooling layer.\n",
    "            cardinality: num of convolution groups.\n",
    "            widen_factor: factor to reduce the input dimensionality before convolution.\n",
    "        \"\"\"\n",
    "        super(ResNeXtBottleneck, self).__init__()\n",
    "        D = cardinality * out_channels // widen_factor\n",
    "        self.conv_reduce = nn.Conv2d(in_channels, D, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn_reduce = nn.BatchNorm2d(D)\n",
    "        self.conv_conv = nn.Conv2d(D, D, kernel_size=3, stride=stride, padding=1, groups=cardinality, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(D)\n",
    "        self.conv_expand = nn.Conv2d(D, out_channels, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn_expand = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_channels != out_channels:\n",
    "            self.shortcut.add_module('shortcut_conv', nn.Conv2d(in_channels, out_channels,\n",
    "                                                                kernel_size=1, stride=stride, padding=0, bias=False))\n",
    "            self.shortcut.add_module('shortcut_bn', nn.BatchNorm2d(out_channels))\n",
    "\n",
    "    def forward(self, x):\n",
    "        bottleneck = self.conv_reduce.forward(x)\n",
    "        bottleneck = F.relu(self.bn_reduce.forward(bottleneck), inplace=True)\n",
    "        bottleneck = self.conv_conv.forward(bottleneck)\n",
    "        bottleneck = F.relu(self.bn.forward(bottleneck), inplace=True)\n",
    "        bottleneck = self.conv_expand.forward(bottleneck)\n",
    "        bottleneck = self.bn_expand.forward(bottleneck)\n",
    "        residual = self.shortcut.forward(x)\n",
    "        return F.relu(residual + bottleneck, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ResidualTailNetwork(nn.Module):\n",
    "    def __init__(self, n_classes=1, widen_factor=4):\n",
    "        super(ResidualTailNetwork, self).__init__()\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.block_depth = 3\n",
    "        self.cardinality = 16\n",
    "        self.widen_factor = widen_factor\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        self.stages = [64 * self.widen_factor, 128 * self.widen_factor, 256 * self.widen_factor]\n",
    "        # self.depths = [2, 3, 4]\n",
    "        self.depths = [3, 4]\n",
    "        self.stage_1 = self.block('stage_1', self.stages[0], self.stages[1], 2)\n",
    "        self.stage_2 = self.block('stage_2', self.stages[1], self.stages[2], 2)\n",
    "\n",
    "        for key in self.state_dict():\n",
    "            if key.split('.')[-1] == 'weight':\n",
    "                if 'conv' in key:\n",
    "                    init.kaiming_normal_(self.state_dict()[key], mode='fan_out')\n",
    "                if 'bn' in key:\n",
    "                    self.state_dict()[key][...] = 1\n",
    "            elif key.split('.')[-1] == 'bias':\n",
    "                self.state_dict()[key][...] = 0\n",
    "\n",
    "        self.avgpool = nn.AvgPool2d(4)\n",
    "        self.fc = nn.Linear(self.stages[-1], self.n_classes)\n",
    "        if self.widen_factor == 1:\n",
    "            self.fc = nn.Linear(self.stages[-1] * 4, self.n_classes) \n",
    "\n",
    "    def block(self, name, in_channels, out_channels, pool_stride=2):\n",
    "        \"\"\" Stack n bottleneck modules where n is inferred from the depth of the network.\n",
    "        Args:\n",
    "            name: string name of the current block.\n",
    "            in_channels: number of input channels\n",
    "            out_channels: number of output channels\n",
    "            pool_stride: factor to reduce the spatial dimensionality in the first bottleneck of the block.\n",
    "        Returns: a Module consisting of n sequential bottlenecks.\n",
    "        \"\"\"\n",
    "        block = nn.Sequential()\n",
    "        for bottleneck in range(self.block_depth):\n",
    "            name_ = '%s_bottleneck_%d' % (name, bottleneck)\n",
    "            if bottleneck == 0:\n",
    "                block.add_module(name_, ResNeXtBottleneck(in_channels, out_channels, pool_stride, self.cardinality,\n",
    "                                                          self.widen_factor))\n",
    "            else:\n",
    "                block.add_module(name_, ResNeXtBottleneck(out_channels, out_channels, 1, self.cardinality,\n",
    "                                                          self.widen_factor))\n",
    "\n",
    "        return block\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stage_1.forward(x)\n",
    "        x = self.stage_2.forward(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Добавьте новую голову self.gender_model, обновите код forward-пасса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetFR(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, emb_size=128, head_size=7*7*512, preserve_resolution=True, **kwargs):\n",
    "        self.inplanes = 64\n",
    "        super(ResNetFR, self).__init__()\n",
    "        if preserve_resolution:\n",
    "            self.body = nn.Sequential(\n",
    "                nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.PReLU())\n",
    "        else:\n",
    "            self.body = nn.Sequential(\n",
    "                nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.PReLU(),\n",
    "                nn.MaxPool2d(\n",
    "                    kernel_size=3,\n",
    "                    stride=2,\n",
    "                    padding=1))\n",
    "            \n",
    "        self.head_size = head_size\n",
    "        self.emb_size = emb_size\n",
    "        self.gender_only = kwargs.get(\"gender_only\", False)\n",
    "\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0], stride=2)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        \n",
    "        if kwargs.get(\"emb_model\", False):\n",
    "            self.head = HeadE(self.head_size, self.emb_size)\n",
    "\n",
    "        # cоздайте голову для предсказания одного числа - вероятности одного из полов. hint: resnext block, widen_factor=4\n",
    "        < ваш код здесь > \n",
    "        \n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def set_parameter_requires_grad(self, layers=set()):\n",
    "        \"\"\"Sets parameters from the heads listed in layers to requires_grad=True.\n",
    "        Args:\n",
    "            layers: Set  of name strings for heads to set requires_grad=True, e.g. {'pose_model'}.\n",
    "        \"\"\"\n",
    "        if layers:\n",
    "            for name, param in self.named_parameters():\n",
    "                if name.split(\".\")[0] in layers:\n",
    "                    param.requires_grad = True\n",
    "                else:\n",
    "                    param.requires_grad = False\n",
    "\n",
    "    def set_parameter_to_train(self, layers=set()):\n",
    "        \"\"\"Sets parameters from the heads listed in layers to train mode.\n",
    "        Args:\n",
    "            layers: Set  of name strings for heads to set to train mode, e.g. {'pose_model'}.\n",
    "        \"\"\"\n",
    "        model.eval()\n",
    "        for layer in layers:\n",
    "            head = getattr(self, layer)\n",
    "            head.train()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = list()\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        device = x.device\n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        x = self.body(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        \n",
    "        # добавьте предсказание пола\n",
    "        < ваш код здесь > \n",
    "        \n",
    "        if self.gender_only:\n",
    "            return male_proba\n",
    "\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        if hasattr(self, 'head'):\n",
    "            embeddings = self.head(x)\n",
    "        else:\n",
    "            embeddings = torch.zeros(batch_size, self.emb_size).detach()\n",
    "\n",
    "        return embeddings, male_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model without emb head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = build_resnet(100, emb_model=False, gender_model=True, gender_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_ft.gender_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# загрузите предобученные веса модели\n",
    "< ваш код здесь>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель работает с тензорами размера 3х112х112. Убедитесь, что она возвращает то, что нам нужно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "< ваш код здесь >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "        \n",
    "        \n",
    "def save_checkpoint(state, is_best_gender=False,  filename='checkpoint'):\n",
    "    torch.save(state, filename + '.pth.tar')\n",
    "    if is_best_gender:\n",
    "        shutil.copyfile(filename + '.pth.tar', filename + '_best_gender.pth.tar')\n",
    "        \n",
    "        \n",
    "def imshow(inp, title=None, figsize=(16, 9)):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.5, 0.5, 0.5])\n",
    "    std = np.array([0.5, 0.5, 0.5])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    \n",
    "    \n",
    "def set_bn_eval(module):\n",
    "    if isinstance(module, torch.nn.modules.batchnorm._BatchNorm):\n",
    "        module.eval()\n",
    "          \n",
    "def set_parameter_requires_grad(model, layers=set()):\n",
    "    \"\"\"Sets parameters from the heads listed in layers to requires_grad=True.\n",
    "    Args:\n",
    "        layers: Set  of name strings for heads to set requires_grad=True, e.g. {'pose_model'}.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    if layers:\n",
    "        for name, param in model.named_parameters():\n",
    "            if name.split(\".\")[0] in layers:\n",
    "                param.requires_grad = True\n",
    "            else:\n",
    "                param.requires_grad = False\n",
    "\n",
    "                \n",
    "def set_parameter_to_train(model, layers=set()):\n",
    "    \"\"\"Sets parameters from the heads listed in layers to train mode.\n",
    "    Args:\n",
    "        layers: Set  of name strings for heads to set to train mode, e.g. {'pose_model'}.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    for layer in layers:\n",
    "        head = getattr(model, layer)\n",
    "        head.train()\n",
    "        enable_running_stats(head)\n",
    "\n",
    "        \n",
    "def disable_running_stats(model):\n",
    "    for module in model.modules():\n",
    "        if hasattr(module, 'track_running_stats'):\n",
    "            module.track_running_stats = False\n",
    "        \n",
    "        \n",
    "def enable_running_stats(model):\n",
    "    for module in model.modules():\n",
    "        if hasattr(module, 'track_running_stats'):\n",
    "            module.track_running_stats = True\n",
    "\n",
    "    \n",
    "def get_trainable_params(model):\n",
    "    if hasattr(model, 'module'):\n",
    "        parameters = model.module.named_parameters()\n",
    "    else:\n",
    "        parameters = model.named_parameters()\n",
    "    \n",
    "    print (\"Parameters to update:\")\n",
    "    params_to_update = []\n",
    "    for name, param in parameters:\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "    return params_to_update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Определим аугментации и загрузим датасеты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "        transforms.Resize(112),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(\n",
    "            brightness=0.4,\n",
    "            contrast=0.4,\n",
    "            saturation=0.4),\n",
    "        transforms.RandomGrayscale(p=0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n",
    "\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "        transforms.Resize(112),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = '/data4/made/gender_dataset/train/'\n",
    "val_folder = '/data4/made/gender_dataset/val/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.ImageFolder(train_folder, train_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = torchvision.datasets.ImageFolder(val_folder, val_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=50, shuffle=True, num_workers=4)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=50, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Посмотрим глазами на выборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_dataset.classes\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(train_dataloader))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs[:10], nrow=10)\n",
    "imshow(out, title=[class_names[x] for x in classes[:10]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train / Val functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch, trainable_params=['gender_model'], device='cuda', print_freq=10):\n",
    "    \n",
    "    # with NLL loss\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    avg_loss = AverageMeter()\n",
    "    \n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    \n",
    "    # set only gender head to train\n",
    "    set_parameter_requires_grad(model, set(trainable_params))\n",
    "    set_parameter_to_train(model_ft, set(trainable_params))\n",
    "\n",
    "        \n",
    "    #set meters\n",
    "    gender_auc_mtr = meter.AUCMeter()\n",
    "        \n",
    "    end = time.time()\n",
    "    for i, (input_tensor, gender_labels) in enumerate(tqdm.tqdm(train_loader)):\n",
    "        \n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        \n",
    "        input_tensor = input_tensor.to(device)\n",
    "        gender_labels = gender_labels.float().to(device)\n",
    "        \n",
    "        # compute output\n",
    "        gender_preds = model(input_tensor).squeeze(1)\n",
    "        \n",
    "        # gender + age\n",
    "        gender_loss = criterion(gender_preds, gender_labels)\n",
    "\n",
    "        avg_loss.update(gender_loss.item(), input_tensor.shape[0])\n",
    "\n",
    "        # compute gradient and do optimizer step\n",
    "        optimizer.zero_grad()\n",
    "        gender_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "        # update gender stats\n",
    "        gender_auc_mtr.add(torch.sigmoid(gender_preds.detach()), gender_labels)\n",
    "                        \n",
    "            \n",
    "    train_gender_roc_auc, _, _= gender_auc_mtr.value()\n",
    "    \n",
    "    return train_gender_roc_auc, avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_dataloader, gender_thresh=0.5, device='cuda'):\n",
    "    gender_auc_mtr = meter.AUCMeter()\n",
    "    gender_confusion_mtr = meter.ConfusionMeter(k=2)\n",
    "    \n",
    "    model.eval().to(device)\n",
    "    running_loss = 0.0\n",
    "    # будем записывать сюда имена файлов, на которых мы ошиблись\n",
    "    gender_mistakes = []\n",
    "    male_index = val_dataloader.dataset.class_to_idx['male']\n",
    "    \n",
    "    for inputs, genders in tqdm.tqdm(val_dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        gender_labels = genders.float().to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            gender_preds = model(inputs)\n",
    "        \n",
    "        gender_preds = torch.sigmoid(gender_preds)\n",
    "        gender_preds_labels = gender_preds > gender_thresh\n",
    "        \n",
    "        gender_mistakes.extend(list(map(int, gender_preds_labels.flatten().long() != \n",
    "                                                            gender_labels.flatten().long())))\n",
    "\n",
    "        # update gender stats\n",
    "        gender_auc_mtr.add(gender_preds, gender_labels)\n",
    "\n",
    "        gender_confusion_mtr.add(torch.nn.functional.one_hot(gender_preds_labels.flatten().long(), num_classes=2), \n",
    "                                 torch.nn.functional.one_hot(gender_labels.flatten().long(), num_classes=2))\n",
    "        \n",
    "    \n",
    "    val_gender_roc_auc, _, _= gender_auc_mtr.value()\n",
    "    val_gender_confusion_matrix = gender_confusion_mtr.value()\n",
    "    val_gender_acc = np.trace(val_gender_confusion_matrix) / np.sum(val_gender_confusion_matrix)\n",
    "    return val_gender_roc_auc, val_gender_acc, val_gender_confusion_matrix, gender_mistakes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Заморозим всё, кроме головы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# disable_running_stats(model_ft)\n",
    "set_parameter_requires_grad(model_ft, ['gender_model'])\n",
    "set_parameter_to_train(model_ft, ['gender_model'])\n",
    "trainable_parameters = get_trainable_params(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_ft.cuda()\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Observe that only part of the parameters are being optimized\n",
    "optimizer_ft = optim.SGD(trainable_parameters, lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_gender_roc_auc = 0.0\n",
    "\n",
    "for epoch in range(100):\n",
    "    train_gender_roc_auc, avg_loss  = train(train_dataloader, model_ft, criterion, optimizer_ft, \n",
    "                                                                    epoch, trainable_params=['gender_model'])\n",
    "    print('Train gender roc-auc %1.5f' % train_gender_roc_auc)\n",
    "    \n",
    "    val_gender_roc_auc, val_gender_acc, val_gender_confusion_matrix, gender_mistakes = validate(model_ft, val_dataloader)\n",
    "    exp_lr_scheduler.step()\n",
    "    \n",
    "    is_best_gender = False\n",
    "    if val_gender_roc_auc > best_gender_roc_auc:\n",
    "        print (\"Best gender model\")\n",
    "        is_best_gender = True\n",
    "        best_gender_roc_auc = val_gender_roc_auc\n",
    "    \n",
    "    \n",
    "    print('Val gender roc-auc %1.5f, \\\n",
    "          Val gender accuracy %1.5f, \\\n",
    "          Best gender roc-auc %1.5f'\n",
    "          % (val_gender_roc_auc, val_gender_acc, best_gender_roc_auc))\n",
    "    \n",
    "    # save mistakes\n",
    "    mistakes_filenames = np.array(val_dataset.samples)[np.argwhere(gender_mistakes).flatten()]\n",
    "    \n",
    "    save_checkpoint({\n",
    "    'epoch': epoch + 1,\n",
    "    'state_dict': model_ft.state_dict(),\n",
    "    'train_gender_roc_auc': train_gender_roc_auc,\n",
    "    'val_gender_roc_auc': val_gender_roc_auc,\n",
    "    'val_gender_accuracy': val_gender_acc,\n",
    "    'optimizer' : optimizer_ft.state_dict(),\n",
    "    'gender_mistakes_filenames': mistakes_filenames,\n",
    "    }, is_best_gender, 'resnet100_workshop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cравним с моделью без гендер-головы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_state_dicts(state_dict_1, state_dict_2):\n",
    "    num_mismatches = 0\n",
    "    for key_1, value_1 in state_dict_1.items():\n",
    "        for key_2, value_2 in state_dict_2.items():\n",
    "            if key_1 == key_2:\n",
    "                if torch.equal(value_1, value_2):\n",
    "                    pass\n",
    "                else:\n",
    "                    print('Mismtach found at', key_1)\n",
    "                    num_mismatches += 1\n",
    "    if num_mismatches == 0:\n",
    "        print (\"All good!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_ft.cpu()\n",
    "compare_state_dicts(torch.load(\"fr.pth.tar\", map_location='cpu'), model_ft.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузим лучшую модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('resnet100_full_05_best_gender.pth.tar', map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Провалидируем её"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_gender_roc_auc, val_gender_acc, val_gender_confusion_matrix, gender_mistakes = validate(model_ft, val_dataloader)\n",
    "print('Val gender roc-auc %1.5f, \\\n",
    "      Val gender accuracy %1.5f'\n",
    "      % (val_gender_roc_auc, val_gender_acc))\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Посмотрим на предсказания модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def pil_loader(path: str) -> Image.Image:\n",
    "    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
    "    with open(path, 'rb') as f:\n",
    "        img = Image.open(f)\n",
    "        return img.convert('RGB')\n",
    "\n",
    "def predict_male_proba(model, file, device='cuda'):\n",
    "    val_transforms = transforms.Compose([\n",
    "        transforms.Resize(112),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n",
    "    \n",
    "    img = pil_loader(file)\n",
    "    img_tensor = val_transforms(img)\n",
    "    img_tensor = img_tensor.unsqueeze(0).to(device)\n",
    "    \n",
    "    model.eval().to(device)\n",
    "    with torch.no_grad():\n",
    "        gender_preds = model(img_tensor)\n",
    "    \n",
    "    male_proba = torch.sigmoid(gender_preds)\n",
    "    \n",
    "    return male_proba.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_filenames = [pair[0] for pair in val_dataset.samples]\n",
    "for file in np.random.choice(val_filenames, 50):\n",
    "    male_proba = predict_male_proba(model_ft, file)\n",
    "    print (\"filename: {}, male_proba: {}\".format(file, male_proba))\n",
    "    show_image(cv2.imread(file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Посмотрим на ошибки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file, label in checkpoint['gender_mistakes_filenames']:\n",
    "    male_proba = predict_male_proba(model_ft, file)\n",
    "    print (\"filename: {}, male_proba: {}\".format(file, male_proba))\n",
    "    show_image(cv2.imread(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_1_7_1",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
